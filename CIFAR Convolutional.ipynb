{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "train_val_dataset = datasets.CIFAR10('.', download=True, train=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10('.', download=True, train=False, transform=transform)\n",
    "ratio = 0.2\n",
    "train_examples = int((1.0-ratio)*len(train_val_dataset))\n",
    "val_examples = int(ratio*len(train_val_dataset))\n",
    "train_dataset, val_dataset = torch.utils.data.dataset.random_split(train_val_dataset,[train_examples,val_examples])\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(training_losses,val_losses,epochs):\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs),training_losses,label=\"Training loss\")\n",
    "    plt.plot(range(epochs),val_losses,label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.title('Loss per epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 3 input channels(RGB), 12 output channels, 3x3 square convolution\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 12, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 12, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 12, out_channels = 24, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 24, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, stride=2, padding=1), # Output size : [batch_size, 48, 16, 16]\n",
    "            \n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(12288,1200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1200,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,10),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        #x = x.view(-1, 320)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,optimizer,epoch,trainloader,criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for index,(images,labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #if index % 10 == 0:\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                #epoch, index * len(images), len(trainloader.dataset),\n",
    "                #100. * index / len(trainloader), loss.item()))\n",
    "    epoch_loss /= len(trainloader)\n",
    "    print(\"Average training loss:\",epoch_loss)\n",
    "    return epoch_loss\n",
    "    \n",
    "def test(model,device,testloader,criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output,labels)\n",
    "            epoch_loss += loss.item()\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    epoch_loss /= len(testloader)\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        epoch_loss, correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n",
    "    return epoch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Martin Dimitrov\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 1.849683449459076\n",
      "Average loss: 1.5566, Accuracy: 4433/10000 (44%)\n",
      "Average training loss: 1.421746862077713\n",
      "Average loss: 1.2980, Accuracy: 5405/10000 (54%)\n",
      "Average training loss: 1.1745632361888885\n",
      "Average loss: 1.1551, Accuracy: 5933/10000 (59%)\n",
      "Average training loss: 0.9568488050937652\n",
      "Average loss: 1.0721, Accuracy: 6252/10000 (63%)\n",
      "Average training loss: 0.7402486313581467\n",
      "Average loss: 1.1310, Accuracy: 6230/10000 (62%)\n",
      "Average training loss: 0.5036747692108154\n",
      "Average loss: 1.2701, Accuracy: 6144/10000 (61%)\n",
      "Average training loss: 0.35156476864814756\n",
      "Average loss: 1.5379, Accuracy: 6150/10000 (62%)\n",
      "Average training loss: 0.2500807348653674\n",
      "Average loss: 1.6284, Accuracy: 6207/10000 (62%)\n",
      "Average training loss: 0.1997713259115815\n",
      "Average loss: 1.8801, Accuracy: 6142/10000 (61%)\n",
      "Average training loss: 0.16453454619981348\n",
      "Average loss: 2.0673, Accuracy: 6095/10000 (61%)\n",
      "Final performance\n",
      "Average loss: 2.0682, Accuracy: 6103/10000 (61%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.068198137199536"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Classifier().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model,device,optimizer,epoch,trainloader,criterion)\n",
    "    val_loss = test(model,device,valloader,criterion)\n",
    "    training_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "print(\"Final performance\")\n",
    "plot_graph(training_losses,val_losses,epochs)\n",
    "test(model,device,testloader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        # batch_size : 64\n",
    "        # Input size to the Autoencoder : [batch_size, 3, 32, 32]\n",
    "        # Output size from the Autoencoder : [batch_size, 3, 32, 32]\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 3 input channels(RGB), 12 output channels, 3x3 square convolution\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 12, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 12, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 12, out_channels = 24, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 24, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, stride=2, padding=1), # Output size : [batch_size, 48, 16, 16]\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # For Upscaling :\n",
    "            # 2x2 kernels can only learn nearest pixel upscaling.\n",
    "            # 3x3 kernels can do bilinear but will require asymmetric padding.\n",
    "            # But 4x4 can do bilinear again without asymmetrical padding.\n",
    "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), # Output size: [batch_size, 24, 32, 32]\n",
    "            nn.ReLU(),  #TODO : try with LeakyReLU while decoding\n",
    "            nn.ConvTranspose2d(24, 12, 3, stride=1, padding=1), # Output size: [batch_size, 12, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 3, stride=1, padding=1), # Output size: [batch_size, 3, 32, 32]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,optimizer,epoch,trainloader,criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for index,(images,labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output,images)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #if index % 10 == 0:\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                #epoch, index * len(images), len(trainloader.dataset),\n",
    "                #100. * index / len(trainloader), loss.item()))\n",
    "    epoch_loss /= len(trainloader)\n",
    "    print(\"Average training loss:\",epoch_loss)\n",
    "    return epoch_loss\n",
    "    \n",
    "def test(model,device,testloader,criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output,images)\n",
    "            epoch_loss += loss.item()\n",
    "    epoch_loss /= len(testloader)\n",
    "    print('Average validation loss: {:.4f}'.format(epoch_loss))\n",
    "    return epoch_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.0031912503452738747\n",
      "Average validation loss: 0.0004\n",
      "Average training loss: 0.0005172801840933972\n",
      "Average validation loss: 0.0003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-464cbe320a9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtraining_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-caf843df200d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, optimizer, epoch, trainloader, criterion)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#if index % 10 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoEncoder().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model,device,optimizer,epoch,trainloader,criterion)\n",
    "    val_loss = test(model,device,valloader,criterion)\n",
    "    training_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "print(\"Final performance\")\n",
    "plot_graph(training_losses,val_losses,epochs)\n",
    "test(model,device,testloader,criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, labels = next(iter(valloader))\n",
    "test_images = test_images.cuda()\n",
    "test_output = model(test_images)\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    fig = plt.figure()\n",
    "    plot = fig.add_subplot(1, 2, 1)\n",
    "    plot.set_title('Original Image')\n",
    "    image_input = np.transpose(test_images[i].cpu(),(1,2,0))\n",
    "    image_output = np.transpose(test_output[i].cpu().detach(),(1,2,0))\n",
    "    imgplot = plt.imshow(image_input)\n",
    "    plot = fig.add_subplot(1, 2, 2)\n",
    "    plot.set_title('Generated Image')\n",
    "    imgplot = plt.imshow(image_output)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mixed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixed, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 3 input channels(RGB), 12 output channels, 3x3 square convolution\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 12, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 12, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 12, out_channels = 24, kernel_size = 3, stride=1, padding=1), # Output size : [batch_size, 24, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = 24, out_channels = 48, kernel_size = 3, stride=2, padding=1), # Output size : [batch_size, 48, 16, 16]\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # For Upscaling :\n",
    "            # 2x2 kernels can only learn nearest pixel upscaling.\n",
    "            # 3x3 kernels can do bilinear but will require asymmetric padding.\n",
    "            # But 4x4 can do bilinear again without asymmetrical padding.\n",
    "            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), # Output size: [batch_size, 24, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(24, 12, 3, stride=1, padding=1), # Output size: [batch_size, 12, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 3, 3, stride=1, padding=1), # Output size: [batch_size, 3, 32, 32]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(12288,1200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1200,500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500,10),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        encoded = encoded.view(encoded.size(0),-1)\n",
    "        predicted = self.classifier(encoded)\n",
    "        return decoded, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,optimizer,epoch,trainloader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for index,(images,labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        decoded,predicted = model(images)\n",
    "        criterion1 = nn.MSELoss()\n",
    "        criterion2 = nn.CrossEntropyLoss()\n",
    "        loss1 = criterion1(decoded,images)\n",
    "        loss2 = criterion2(predicted,labels)\n",
    "        loss = loss1+loss2\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        #if index % 10 == 0:\n",
    "            #print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                #epoch, index * len(images), len(trainloader.dataset),\n",
    "                #100. * index / len(trainloader), loss.item()))\n",
    "    epoch_loss /= len(trainloader)\n",
    "    print(\"Average training loss:\",epoch_loss)\n",
    "    return epoch_loss\n",
    "    \n",
    "def test(model,device,testloader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            decoded, predicted = model(images)\n",
    "            criterion1 = nn.MSELoss()\n",
    "            criterion2 = nn.CrossEntropyLoss()\n",
    "            loss1 = criterion1(decoded,images)\n",
    "            loss2 = criterion2(predicted,labels)\n",
    "            loss = loss1+loss2\n",
    "            epoch_loss += loss.item()\n",
    "            pred = predicted.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "    epoch_loss /= len(testloader)\n",
    "    print('Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        epoch_loss, correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mixed().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model,device,optimizer,epoch,trainloader)\n",
    "    val_loss = test(model,device,valloader)\n",
    "    training_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "print(\"Final performance\")\n",
    "plot_graph(training_losses,val_losses,epochs)\n",
    "test(model,device,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, labels = next(iter(valloader))\n",
    "test_images = test_images.cuda()\n",
    "test_output, predicted = model(test_images)\n",
    "print(test_images.shape)\n",
    "print(test_output.shape)\n",
    "for i in range(len(test_images)):\n",
    "    fig = plt.figure()\n",
    "    plot = fig.add_subplot(1, 2, 1)\n",
    "    plot.set_title('Original Image ' + str(classes[labels[i]]))\n",
    "    image_input = np.transpose(test_images[i].cpu(),(1,2,0))\n",
    "    image_output = np.transpose(test_output[i].cpu().detach(),(1,2,0))\n",
    "    imgplot = plt.imshow(image_input)\n",
    "    plot = fig.add_subplot(1, 2, 2)\n",
    "    plot.set_title('Generated Image ' + str(classes[labels[i]]))\n",
    "    imgplot = plt.imshow(image_output)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
